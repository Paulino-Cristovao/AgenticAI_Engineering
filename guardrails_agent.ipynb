{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d39084e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d33c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fcdf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61231e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Ensure the API keys are loaded correctly\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set. Please set it in your .env file.\")\n",
    "else:\n",
    "    openai.api_key = openai_api_key\n",
    "\n",
    "if gemini_api_key is None:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not set. Please set it in your .env file.\")\n",
    "else:\n",
    "    # Return both API keys\n",
    "    (openai_api_key, gemini_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a09d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools: Simulate Order Status Lookup Tool\n",
    "# ----------------------------------------\n",
    "def tool_get_order_status(order_id):\n",
    "    if not order_id:\n",
    "        return \"Order ID is required to fetch the order status.\"\n",
    "    return f\"Order {order_id} was shipped on May 13 and is expected to arrive by May 17.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d04fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardrails Tool: Enforce Policy Compliance\n",
    "# ----------------------------------------\n",
    "def tool_enforce_guardrails(message):\n",
    "    blocked_keywords = [\"refund after 30 days\", \"free for all\", \"unlimited returns\"]\n",
    "    for keyword in blocked_keywords:\n",
    "        if keyword.lower() in message.lower():\n",
    "            return f\"‚ö†Ô∏è Guardrail Alert: Message contains restricted phrase '{keyword}'. Please revise.\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cfcb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Professional System Prompt\n",
    "# ----------------------------\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI-powered multilingual customer support assistant working for a premium ecommerce brand.\n",
    "Your mission is to help customers resolve their inquiries effectively, professionally, and empathetically.\n",
    "\n",
    "Always adhere to the following rules:\n",
    "1. Answer in the language used by the customer (English, French, Spanish, Portuguese, or German).\n",
    "2. Keep your tone polite, friendly, and brand-consistent (e.g., professional, warm, and clear).\n",
    "3. Do NOT promise anything beyond the provided policies.\n",
    "4. Only use tools or resources you are provided with.\n",
    "5. If you do not have the answer, ask the customer for clarification.\n",
    "\n",
    "### Company Policy:\n",
    "Return Policy: \"We accept returns within 30 days of purchase if items are unused and in original packaging.\"\n",
    "Shipping Policy: \"Orders are typically shipped within 2 business days and delivered within 5-7 days.\"\n",
    "\n",
    "Ensure your responses are accurate, helpful, and policy-compliant. Avoid speculative or misleading information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8897528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant memory (in-session only)\n",
    "# ----------------------------\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc85efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant Completion Function with Async and Guardrails\n",
    "# ----------------------------\n",
    "def ask_openai_agent(user_message, language, order_id=None):\n",
    "    global chat_history\n",
    "\n",
    "    tool_context = tool_get_order_status(order_id) if order_id else \"\"\n",
    "    guardrail_warning = tool_enforce_guardrails(user_message)\n",
    "\n",
    "    if guardrail_warning:\n",
    "        return guardrail_warning\n",
    "\n",
    "    user_prompt = f\"Customer message (Language: {language}): {user_message}\\n{tool_context}\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    ] + chat_history + [\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            temperature=0.4,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        reply = response.choices[0].message.content\n",
    "        chat_history.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        return reply\n",
    "    except Exception as e:\n",
    "        return f\"[Error from OpenAI API]: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "640d6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the conversation\n",
    "# ----------------------------\n",
    "def summarize_conversation():\n",
    "    if not chat_history:\n",
    "        return \"No conversation to summarize.\"\n",
    "    summary_prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"Summarize the following customer support conversation in a professional tone.\"},\n",
    "        *chat_history\n",
    "    ]\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=summary_prompt\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"[Error summarizing conversation]: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab098027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "# ----------------------------\n",
    "def respond_to_customer(message, language, order_id):\n",
    "    return ask_openai_agent(message, language, order_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a408f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_chat():\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    return \"Chat memory has been cleared.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8580f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize log_data as an empty list if not already defined\n",
    "log_data = []\n",
    "\n",
    "def download_log():\n",
    "    df = pd.DataFrame(log_data)\n",
    "    return df.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f668e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üõçÔ∏è Multilingual AI Customer Support Assistant\n",
    "    - Uses OpenAI GPT-4 with context-aware prompting and simulated tools.\n",
    "    - Responds to customer queries in multiple languages (EN, FR, ES, PT, DE).\n",
    "    - Enforces brand tone, policies, and safety guardrails as callable tools.\n",
    "    - Includes feedback logging and conversation summarization.\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(label=\"Customer Message\", placeholder=\"Enter customer inquiry...\", lines=2)\n",
    "        language = gr.Dropdown([\"English\", \"French\", \"Spanish\", \"Portuguese\", \"German\"], value=\"English\", label=\"Language\")\n",
    "        order_id = gr.Textbox(label=\"Order ID (optional)\")\n",
    "\n",
    "    output = gr.Textbox(label=\"AI Assistant Response\", lines=3)\n",
    "    feedback = gr.Radio([\"üëç Helpful\", \"üëé Unhelpful\"], label=\"Was this response helpful?\")\n",
    "    notes = gr.Textbox(label=\"Additional Feedback\", placeholder=\"Your thoughts...\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit = gr.Button(\"Send\")\n",
    "        clear = gr.Button(\"Clear Memory\")\n",
    "        summarize = gr.Button(\"Summarize Chat\")\n",
    "        download = gr.Button(\"üì• Export Log\")\n",
    "\n",
    "    submit.click(fn=respond_to_customer, inputs=[message, language, order_id], outputs=output)\n",
    "    clear.click(fn=clear_chat, outputs=output)\n",
    "    summarize.click(fn=summarize_conversation, outputs=output)\n",
    "    download.click(fn=download_log, outputs=gr.File(label=\"Download CSV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ed6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/linoospaulinos/miniforge3/envs/py-learn-py310/lib/python3.10/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/linoospaulinos/miniforge3/envs/py-learn-py310/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/linoospaulinos/miniforge3/envs/py-learn-py310/lib/python3.10/site-packages/gradio/blocks.py\", line 2054, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "  File \"/Users/linoospaulinos/miniforge3/envs/py-learn-py310/lib/python3.10/site-packages/gradio/blocks.py\", line 1860, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"/Users/linoospaulinos/miniforge3/envs/py-learn-py310/lib/python3.10/site-packages/gradio/components/file.py\", line 223, in postprocess\n",
      "    size=Path(value).stat().st_size,\n",
      "  File \"/Users/linoospaulinos/miniforge3/envs/py-learn-py310/lib/python3.10/pathlib.py\", line 1097, in stat\n",
      "    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '\\n'\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df9242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-learn-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
